---
title: "Homework 1A"
author: "Rohan Avuthu"
date: "2024-01-20"
output:
  html_document:
    df_print: paged
  pdf_document:
    number_sections: true
---

```{r setup, include=FALSE}
# some useful settings
knitr::opts_chunk$set(echo = TRUE, tidy.opts = list(width.cutoff = 55), tidy = TRUE, fig.align="center")
```

# Problem 1

## Part (a)
```{r}
setwd("~/Desktop/ravuthuecon124")
cheese <- read.csv('survey.csv')
abc <- read.csv('fakenews.csv')
```
This loads a CSV file from the `data` folder. The `data` folder must be in the same folder as this `.Rmd` file. If it's not, you have to specify the right path relative to the current directory containing this `.Rmd` file.

## Part (b)
The sample described in the "survey.csv" consists of 1,208 U.S. adults who participated in an online survey conducted in late November 2016. This sample is not random, likely because it was gathered through an online platform, which can introduce selection bias by primarily including respondents who have internet access and are inclined to participate in online surveys. Such a sample might systematically differ from the general U.S. population as it could overrepresent certain demographics such as younger individuals, those with higher levels of education, and possibly those more engaged with digital technologies and social media. These factors can affect the representativeness of the survey, skewing findings toward the views and behaviors of more technologically adept and politically engaged individuals.

# Problem 2
```{r}
x <- sum(na.omit(abc$fb_share[abc$pro == "Trump"]))

y <- sum(na.omit(abc$fb_share[abc$pro == "Clinton"]))
```

## Part (b)
```{r}
cat(x, "pro-Trump articles were shared on Facebook, and", y, "pro-Clinton articles were shared, in this dataset.")
```

It seems that there were many more pro-Trump articles shared. 

# Problem 3
```{r}
head(abc)
sum(abc$buzzfeed)
sum(abc$snopes)
sum(abc$politifact)

subsample = (abc$buzzfeed == 1 & abc$snopes == 0 & abc$politifact == 0)[abc$buzzfeed == 1]

subsample2 = (abc$buzzfeed == 0 & abc$snopes == 1 & abc$politifact == 0)[abc$snopes == 1]

subsample3 = (abc$buzzfeed == 0 & abc$snopes == 0 & abc$politifact == 1)[abc$politifact == 1]

round(mean(subsample)*100)
round(mean(subsample2)*100)
round(mean(subsample3)*100)
```
The database contains the highest share of exclusive article is Snopes. 

# Problem 4
```{r}

average_media_time <- mean(cheese$MediaMinutesPerDay)

consumed_news <- cheese$MediaMinutesPerDay > 0


average_percentage_social_media <- mean((cheese$SocialMediaMinutesPerDay / cheese$MediaMinutesPerDay)[consumed_news] * 100)

cat("Average media minutes per day:", round(average_media_time), sep=" ")
cat("Average percentage of media time spent on social media:", round(average_percentage_social_media), "%", sep=" ")
```

# Problem 5
```{r}
table(cheese$MostImportantSource)
barplot(sort(table(cheese$MostImportantSource)))
```



